{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e100ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.retrievers import BM25Retriever\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68049b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf56a34",
   "metadata": {},
   "source": [
    "![Diagram](./images/Hybrid_Rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d4cde",
   "metadata": {},
   "source": [
    "# What is Hybrid RAG?\n",
    "\n",
    "So far, we've relied on semantic search (using vector embeddings) to find documents that are conceptually similar to our query. This is powerful, but sometimes you need the precision of a good old-fashioned keyword search (also known as lexical search). Hybrid RAG combines both methods to get the best of both worlds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856fd015",
   "metadata": {},
   "source": [
    "# Set up Retreivers\n",
    "\n",
    "A hybrid RAG system uses multiple retrievers to fetch documents. In this tutorial, we will use a combination of a vector-based (semantic) retriever and a keyword-based retriever.\n",
    "\n",
    "We'll start by loading an existing ChromaDB collection that contains our documents and their embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve original docs from existing Chromadb collection\n",
    "\n",
    "#define the embeddings model\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"2_metadata_filtering_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\",  # Where to save data locally\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713c10c1",
   "metadata": {},
   "source": [
    "### Vector search retreiver\n",
    "\n",
    "This retriever performs a semantic search. It finds documents that are conceptually similar to the query, even if they don't share the exact same keywords. We configure it to return the top 3 most similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2157d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chroma_retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fbe72d",
   "metadata": {},
   "source": [
    "### Keyword search retreiver\n",
    "\n",
    "Next, we set up a `BM25Retriever`. BM25 is a popular algorithm for information retrieval that ranks documents based on the frequency of the query terms in each document, while also accounting for document length. This is a \"sparse\" retrieval method because it relies on matching keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fetch the documents already available in the vector store instead of scraping again\n",
    "records = vector_store.get()\n",
    "docs = [Document(page_content = doc, metadata = meta) for doc, meta in zip(records['documents'], records['metadatas'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab5c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can create the BM25Retriever from these documents and set it to return the top 3 results.\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = 3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73814f",
   "metadata": {},
   "source": [
    "# Retreival & Generation\n",
    "\n",
    "With our retrievers in place, we can now define the generation part of our RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d5476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the llm\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")  \n",
    "\n",
    "#set the prompt template\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "rag_prompt_template = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c2635",
   "metadata": {},
   "source": [
    "### Re-ranking with Reciprocal Rank Fusion\n",
    "\n",
    "We will retrieve documents from both of our retrievers and then use a re-ranking algorithm to create a final, unified list of the most relevant documents.\n",
    "\n",
    "Reciprocal Rank Fusion is a method that combines multiple ranked lists into a single, more robust list. It calculates a new score for each document based on its rank in the different retrieved lists. The formula gives more weight to documents that appear higher up in the rankings across the different lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Ranking algorithm\n",
    "def reciprocal_rank_fusion(retrieved_lists, k=60):\n",
    "    \"\"\"\n",
    "    Reranks documents using the Reciprocal Rank Fusion algorithm.\n",
    "    \n",
    "    Args:\n",
    "        retrieved_lists: A list of lists, where each inner list contains\n",
    "                         retrieved Document objects.\n",
    "        k: A constant used in the RRF formula. Default is 60.\n",
    "\n",
    "    Returns:\n",
    "        A single list of documents, reranked and unique.\n",
    "    \"\"\"\n",
    "    # Dictionary to hold the RRF scores for each document\n",
    "    fused_scores = {}\n",
    "    # Dictionary to store the Document objects themselves, keyed by their content\n",
    "    doc_map = {}\n",
    "\n",
    "    # Iterate through each list of retrieved documents\n",
    "    for doc_list in retrieved_lists:\n",
    "        # Iterate through each document in the list with its rank\n",
    "        for rank, doc in enumerate(doc_list):\n",
    "            content = doc.page_content\n",
    "            if content not in fused_scores:\n",
    "                fused_scores[content] = 0\n",
    "                doc_map[content] = doc # Store the document object\n",
    "            \n",
    "            # Add the RRF score\n",
    "            fused_scores[content] += 1 / (k + rank + 1)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order\n",
    "    reranked_results = sorted(fused_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # Extract the sorted Document objects\n",
    "    reranked_docs = [doc_map[content] for content, score in reranked_results]\n",
    "    scores = [ score for content,score in reranked_results]\n",
    "    return reranked_docs, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"what is the Economic Futures Program?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0efa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve relevant docs from both retrievers\n",
    "chroma_docs = chroma_retriever.invoke(user_question)\n",
    "bm25_docs = bm25_retriever.invoke(user_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed06be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets inspect the results form each retreiver\n",
    "\n",
    "for doc in chroma_docs:\n",
    "    print('-- chroma --', doc.page_content)\n",
    "\n",
    "print(\"-\"*100)\n",
    "\n",
    "for doc in bm25_docs:\n",
    "    print('-- bm25 --',doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e1fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerank the results using Reciprocal Rank Fusion\n",
    "reranked_docs, scores = reciprocal_rank_fusion([chroma_docs, bm25_docs])\n",
    "for doc in reranked_docs:\n",
    "    print('-- reranked --',doc.page_content)\n",
    "\n",
    "print('scores: ', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Answer\n",
    "\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in reranked_docs)\n",
    "prompt = rag_prompt_template.invoke({\"question\": user_question, \"context\": docs_content})\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "#generated response\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd3a94",
   "metadata": {},
   "source": [
    "# Ensemble Retreiver\n",
    "\n",
    "LangChain provides a convenient `EnsembleRetriever` that automates the process of combining and re-ranking results from multiple retrievers. It uses a weighted version of Reciprocal Rank Fusion internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1640c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"what is the Economic Futures Program?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe09fc8",
   "metadata": {},
   "source": [
    "We instantiate the EnsembleRetriever with our two retrievers and assign them weights. In this case, we'll give them equal importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f9f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EnsembleRetriever (hybrid)\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[chroma_retriever, bm25_retriever],\n",
    "    weights=[0.5, 0.5]  # adjust weights as needed\n",
    ")\n",
    "\n",
    "retreived_docs = ensemble_retriever.invoke(user_question)\n",
    "\n",
    "#inspect retreived docs\n",
    "for doc in retreived_docs:\n",
    "    print('-- ensemble --',doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e402a",
   "metadata": {},
   "source": [
    "Now, we can directly use the documents retrieved by the EnsembleRetriever to generate our final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Answer\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in reranked_docs)\n",
    "prompt = rag_prompt_template.invoke({\"question\": user_question, \"context\": retreived_docs})\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "#generated response\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
